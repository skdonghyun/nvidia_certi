## **Lesson 14: 오케스트레이션, MLOps 및 작업 스케줄링**

### **강의 개요**

이 단원에서는 **오케스트레이션**과 **작업 스케줄링**에 대해 다룹니다. **Kubernetes**와 **머신러닝 운영(MLOps)**, 그리고 **Slurm 스케줄러**에 대해 논의합니다.

### **학습 목표**

이 단원을 마치면 다음을 수행할 수 있습니다:

- **오케스트레이션과 스케줄링의 차이점 설명**: 두 개념의 정의와 용도를 이해합니다.
- **오케스트레이션과 스케줄링에 사용되는 일반적인 도구 설명**: Kubernetes, Slurm 등의 도구에 대해 학습합니다.
- **MLOps 도구의 가치 논의**: MLOps가 AI 프로젝트에 어떻게 도움이 되는지 이해합니다.

---

### **핵심 내용 분석**

#### **1. 오케스트레이션과 스케줄링의 개념**

- **오케스트레이션(Container Orchestration)**:

  - **정의**: 컨테이너와 관련된 운영을 자동화하는 방법입니다.
  - **역할**: 컨테이너의 배포, 스케일링, 네트워킹 등을 관리합니다.
  - **특징**:
    - **컨테이너 기반**으로 작동합니다.
    - **마이크로서비스** 아키텍처를 지원합니다.
    - 추론(inferencing) 요구에 따라 **스케일 업/다운**이 가능합니다.
    - **로드 밸런싱**을 통해 트래픽을 분산합니다.
    - 고급 기능을 위해 추가적인 메타 스케줄러가 필요할 수 있습니다.

- **스케줄링(Scheduling)**:

  - **정의**: 사용 가능한 컴퓨팅 자원에 워크로드를 할당하는 프로세스입니다.
  - **역할**: 작업과 잡을 적절한 자원에 배치하여 실행합니다.
  - **특징**:
    - **베어 메탈 기반**이지만 컨테이너도 지원합니다.
    - **고성능 컴퓨팅(HPC)** 환경을 위해 설계되었습니다.
    - 추론 기능이 없습니다.
    - **우선순위**와 **프리엠션** 등의 고급 기능이 내장되어 있습니다.
    - 로드 밸런싱보다는 **자원 할당**에 초점을 둡니다.

#### **2. Kubernetes 소개**

- **Kubernetes**:

  - 오픈 소스 컨테이너 오케스트레이션 시스템으로, 소프트웨어의 배포, 스케일링 및 관리를 자동화합니다.
  - **구글**에서 처음 설계했으며, 현재는 **Cloud Native Computing Foundation**에서 유지 관리하고 있습니다.

- **작동 방식**:

  1. **컨테이너 기반 작업 정의**: 예를 들어, CUDA 컨테이너가 `nvidia-smi` 명령을 실행하도록 설정하고, 1개의 GPU가 필요한 노드에서 실행되도록 합니다.
  2. **마스터 노드 결정**: 마스터 노드는 작업 기준에 부합하는 워커 노드를 결정합니다.
  3. **작업 배포**: 해당 워커 노드에 작업을 배포합니다.
  4. **Pod 실행**: 워커 노드에서 애플리케이션으로 실행되는 **Pod**는 컨테이너 그룹입니다.

- **주요 구성 요소**:

  - **노드(Node)**: CPU, 메모리, GPU 등의 자원을 가진 서버입니다.
  - **클러스터(Cluster)**: 컨테이너화된 워크로드를 실행할 수 있는 노드들의 모음입니다.
  - **네임스페이스(Namespace)**: 멀티 테넌시를 위한 격리된 환경으로, 자원 간의 충돌을 방지합니다.
  - **컨테이너(Container)**: 필요한 종속성을 포함한 독립 실행형 런타임입니다.
  - **Pod**: 하나 이상의 컨테이너 그룹으로, 단일 애플리케이션으로 제어됩니다.
  - **퍼시스턴트 볼륨(Persistent Volume)**: Pod 내 컨테이너들이 공유하는 스토리지로, 데이터가 컨테이너 재시작 시에도 유지됩니다.
  - **서비스(Services)**: 네트워킹 및 Pod의 배포, 복제본 생성 등을 처리합니다.

#### **3. NVIDIA GPU Operator**

- **정의**: Kubernetes에서 GPU를 사용하기 위해 필요한 모든 NVIDIA 소프트웨어의 배포 및 관리를 자동화하는 오픈 소스 소프트웨어입니다.
- **기능**:
  - **NVIDIA DCGM**(데이터 센터 GPU 관리자)을 포함하여 클러스터 환경에서 GPU를 관리하고 모니터링합니다.
  - GPU 관리 작업을 단순화하고 자원 신뢰성과 가동 시간을 향상시킵니다.
- **이점**: Kubernetes에서 GPU 가속 애플리케이션을 신속하고 오류 없이 확장할 수 있습니다.

#### **4. NVIDIA Network Operator**

- **정의**: Kubernetes에서 **GPUDirect RDMA**(원격 직접 메모리 액세스)를 활성화하기 위한 도구입니다.
- **기능**:
  - **MLNX_OFED**: NVIDIA 네트워킹 팀에서 제공하는 네트워킹 라이브러리 및 드라이버 세트를 설치합니다.
  - **네트워크 구성 요소 설치**: Kubernetes 클러스터에서 RDMA와 GPUDirect를 활성화하기 위한 호스트 네트워킹 구성 요소를 설치합니다.
- **작동 방식**: GPU Operator와 함께 작동하여 네트워킹 소프트웨어를 배포합니다.

#### **5. 머신러닝 운영(MLOps)**

- **정의**: AI 프로젝트의 운영과 배포에 체계적인 방법론을 도입하여 AI 인프라 활용을 최적화하는 도구입니다.
- **주요 기능**:
  - 데이터 준비 및 버전 관리
  - 모델 및 파라미터 버전 관리
  - 실험 및 결과 모니터링
  - 모델의 배포 및 성능 모니터링
- **이점**:
  - 사용자 생산성 향상 및 워크플로우 가속화
  - 자원 활용 극대화
  - 프로젝트 확장 지원
- **NVIDIA의 MLOps 파트너**:
  - 다양한 MLOps 기능을 제공하는 여러 파트너가 있으며, 자세한 정보는 NVIDIA 웹사이트에서 확인할 수 있습니다.

#### **6. Slurm 스케줄러**

- **정의**: SchedMD에서 개발한 작업 스케줄링 및 클러스터 관리 도구입니다.
- **특징**:
  - Linux 클러스터를 위한 오픈 소스 시스템으로, 확장성과 결함 허용성이 높습니다.
  - 커널 수정 없이 동작하며, 클러스터 자원의 일부에서 작업을 실행하도록 스케줄링합니다.
  - AI 훈련에 적합하며, Unix/Linux 시스템과 밀접하게 통합되어 있습니다.
- **시스템 디자인**:
  - **Slurm 컨트롤러**: 중앙 관리자 역할로, 워크로드와 클러스터의 자원을 관리합니다.
  - **컴퓨트 노드**: 작업을 실행하고 결과를 반환합니다.
  - **사용자 명령 흐름**: 사용자는 Slurm 컨트롤러에 명령을 보내고, 컨트롤러는 작업을 컴퓨트 노드에 스케줄링합니다.
- **컨테이너 사용**:
  - **Enroot**와 **Pyxis**: NVIDIA의 도구로, Slurm에서 컨테이너를 사용하도록 지원합니다.
    - **Enroot**: 컨테이너를 비권한 샌드박스로 변환합니다.
    - **Pyxis**: Enroot를 Slurm과 통합하여 컨테이너 실행을 지원합니다.