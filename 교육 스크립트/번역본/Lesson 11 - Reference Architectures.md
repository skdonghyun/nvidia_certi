## **Lesson 11: 레퍼런스 아키텍처**

### **강의 개요**

이 단원에서는 **NVIDIA 레퍼런스 아키텍처**에 대해 다룹니다. 레퍼런스 아키텍처의 개요와 그 이점을 살펴보고, **DGX BasePOD 레퍼런스 아키텍처**를 사용하여 레퍼런스 아키텍처에서 찾을 수 있는 정보 유형을 보여줍니다. 마지막으로, **DGX SuperPOD** 및 추가 레퍼런스 아키텍처에 대해 간략히 살펴봅니다.

### **학습 목표**

이 단원을 마치면 다음을 수행할 수 있습니다:

- **레퍼런스 아키텍처의 가치 설명**: 레퍼런스 아키텍처가 왜 중요한지, 어떤 이점을 제공하는지 이해합니다.
- **레퍼런스 아키텍처에서 찾을 수 있는 정보 설명**: 레퍼런스 아키텍처에 어떤 정보가 포함되어 있는지 파악합니다.
- **사용 가능한 NVIDIA 레퍼런스 아키텍처 식별**: NVIDIA에서 제공하는 다양한 레퍼런스 아키텍처를 알아봅니다.
- **NVIDIA BasePOD 레퍼런스 아키텍처의 구성 요소 설명**: BasePOD의 주요 구성 요소와 그 역할을 이해합니다.

---

### **핵심 내용 분석**

#### **1. 레퍼런스 아키텍처 개요**

- **레퍼런스 아키텍처란**: 시스템 구현을 위한 권장 설계를 보여주는 문서로, 고성능 솔루션을 제공하기 위해 최상의 설계를 사용합니다.
- **복잡한 컴퓨팅 환경**: 여러 컴퓨팅 서버, 시스템을 연결하는 네트워킹 패브릭, 데이터 스토리지, 관리 서버 등 다양한 구성 요소로 이루어져 있습니다.
- **레퍼런스 아키텍처의 이점**:
  - **문제 해결을 위한 특정 설계 제시**: 특정 요구 사항에 맞는 솔루션을 제공합니다.
  - **기본 설계 제공**: 조직의 필요에 따라 맞춤화할 수 있는 기본 설계를 제공합니다.
  - **설계 및 계획 비용과 시간 절감**: 빠른 솔루션 도출을 가능하게 합니다.
  - **품질 및 신뢰성 향상**: 복잡성을 줄여 품질과 신뢰성을 높입니다.

#### **2. NVIDIA DGX BasePOD 레퍼런스 아키텍처**

- **DGX BasePOD 소개**:
  - **구성 요소**:
    - **NVIDIA DGX 시스템**: 고성능 컴퓨팅을 위한 핵심 컴퓨팅 장치.
    - **NVIDIA 네트워킹 시스템**: 고속 데이터 전송을 위한 네트워크 인프라.
    - **NVIDIA Base Command 소프트웨어**: 시스템 통합과 관리를 위한 소프트웨어.
    - **NVIDIA AI Enterprise 소프트웨어**: AI 워크로드를 지원하는 소프트웨어 스택.
    - **파트너 스토리지 솔루션**: 신뢰할 수 있는 스토리지 제공업체의 솔루션.
  - **레퍼런스 아키텍처의 내용**:
    - **구성 요소 및 연결 정의**: 최대 16개의 DGX B200 또는 H100 시스템으로 구성된 BasePOD를 구축하기 위한 구성 요소와 연결 방법을 정의합니다.
    - **다양한 구성 제공**: 다양한 요구 사항에 맞는 여러 가지 구성 옵션을 제공합니다.
  - **접근 방법**: 제공된 링크를 통해 레퍼런스 아키텍처 문서에 접근할 수 있습니다.

- **DGX BasePOD의 통합 솔루션**:
  - **컴퓨팅**: 업계 선두의 DGX 시스템.
  - **네트워킹**: 검증된 NVIDIA 네트워킹 제품.
  - **스토리지**: 신뢰할 수 있는 NVIDIA 파트너의 스토리지 솔루션.
  - **소프트웨어 통합**: NVIDIA Base Command와 NVIDIA AI Enterprise를 통해 전체 스택 솔루션을 제공합니다.

- **DGX BasePOD의 주요 구성 요소**:
  - **DGX 시스템**:
    - **DGX B200 시스템**:
      - **GPU**: 8개의 NVIDIA B200 GPU 탑재.
      - **성능**: 72페타플롭스(FP8) 훈련 성능, 144페타플롭스(FP4) 추론 성능.
      - **적합성**: 모든 엔터프라이즈 AI 워크로드에 적합.
    - **DGX H100 시스템**:
      - **GPU**: 8개의 NVIDIA H100 GPU 탑재.
      - **성능**: 32페타플롭스(FP8).
      - **특징**: AI 개발을 위한 강력한 시스템.
    - **공통 특징**:
      - **1기가비트 이더넷 포트**: 베이스보드 관리 컨트롤러(BMC)를 통한 아웃오브밴드 관리 제공.
      - **BMC 기능**: 시스템이 꺼져 있어도 원격 관리 가능.
  
  - **네트워킹 어댑터**:
    - **NVIDIA ConnectX-7 네트워크 어댑터**:
      - **구성 옵션**: InfiniBand 또는 Ethernet 연결로 구성 가능.
      - **사용 용도**:
        - **InfiniBand**: 컴퓨트 네트워크에 사용.
        - **Ethernet**: 스토리지, 인밴드 관리, 아웃오브밴드 관리 네트워크에 사용.

  - **스위치 장비**:
    - **InfiniBand 스위치**:
      - **QM9700 NDR InfiniBand 스위치**: 400Gbps의 속도로 DGX H100 시스템과 함께 사용.
      - **QM8700 스위치**: 다른 구성에서 사용 가능.
    - **Ethernet 스위치**:
      - **SN5600**: GPU 간 패브릭용으로 사용되며, 10GbE에서 800GbE까지의 속도를 제공합니다.
      - **SN4600**: 인밴드 관리 및 스토리지 패브릭용으로 사용되며, 1GbE에서 200GbE까지의 속도를 제공합니다.
      - **SN2201**: 아웃오브밴드 관리 연결용으로 사용되며, 1GbE에서 100GbE까지의 속도를 제공합니다.

  - **구성 예시**:
    - **DGX H100 BasePOD 구성**:
      - **컴퓨트 네트워크**: QM9700 스위치를 사용하여 NDR 200Gbps InfiniBand 연결 구성.
      - **네트워크 어댑터**: ConnectX-7 사용.
      - **스토리지 및 관리 네트워크**: SN4600 스위치를 사용한 Ethernet 네트워크.
      - **지원 시스템 수**: 2에서 16개의 DGX H100 시스템에 적용 가능.
    - **동일한 아키텍처의 활용성**: 동일한 DGX BasePOD 레퍼런스 아키텍처를 DGX B200 시스템과 함께 사용할 수 있습니다.

#### **3. DGX SuperPOD 및 추가 레퍼런스 아키텍처**

- **DGX SuperPOD 소개**:
  - **차세대 AI 슈퍼컴퓨팅 인프라**: DGX B200 또는 DGX H100 시스템 기반.
  - **스케일러블 유닛(SU)**:
    - **정의**: 모듈식 배포를 가능하게 하는 컴퓨트 빌딩 블록.
    - **구성**: 최대 127개의 노드로 구성된 SuperPOD 구축 가능.
  - **구성 요소**:
    - **NVIDIA 네트워킹 스위치**: 고속 데이터 전송 지원.
    - **소프트웨어 스토리지**: 데이터 관리 및 저장.
    - **NVIDIA AI Enterprise**: AI 개발 및 배포를 간소화하는 완전 지원 소프트웨어 스위트.
  - **추천 네트워킹**: 대규모 언어 모델(GPT-4 등)을 훈련하기 위해 InfiniBand 네트워킹을 사용하는 것이 권장됩니다.
  - **배포 사례**: 전 세계의 고객 데이터 센터와 클라우드 서비스 제공업체에서 배포되었습니다.

- **기타 레퍼런스 아키텍처**:
  - **NVIDIA AI Enterprise 레퍼런스 아키텍처**: 특정 NVIDIA 서버에 기반하지 않은 아키텍처.
  - **Cloudera 데이터 플랫폼 레퍼런스 아키텍처**: 노드 구성, 네트워크 토폴로지, 배포 토폴로지 등 디자인을 최대한 활용하기 위한 리소스를 포함합니다.