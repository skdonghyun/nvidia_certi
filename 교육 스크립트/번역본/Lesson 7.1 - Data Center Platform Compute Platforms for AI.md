## **Lesson 7.1: 데이터 센터 플랫폼 | AI를 위한 컴퓨트 플랫폼**

### **강의 개요**

이 단원에서는 **AI를 위한 컴퓨트 플랫폼**에 대해 다룹니다. 주요 주제로는 데이터 센터 플랫폼, AI 데이터 센터를 위한 GPU와 CPU, 멀티-GPU 시스템 소개, DPU(Data Processing Unit) 소개, 그리고 NVIDIA 인증 시스템 등이 포함됩니다.

### **학습 목표**

이 단원을 마치면 다음을 수행할 수 있습니다:

- **NVIDIA 데이터 센터 플랫폼의 주요 구성 요소와 특징 식별**: NVIDIA의 데이터 센터 플랫폼이 무엇이며, 어떤 구성 요소와 특징을 갖고 있는지 이해합니다.
- **AI 데이터 센터를 위한 GPU와 CPU 요구사항 및 다양한 제품과 그 사용 사례 식별**: AI 데이터 센터에서 어떤 GPU와 CPU가 필요하며, 어떤 제품들이 있고 그들이 어떤 사용 사례에 적합한지 이해합니다.
- **멀티-GPU 시스템의 목적과 기능 이해**: 멀티-GPU 시스템이 무엇이며, 어떤 역할과 능력을 갖고 있는지 이해합니다.
- **멀티-노드 GPU 인터커넥트 기술 설명**: 여러 노드의 GPU를 연결하는 기술이 어떻게 작동하는지 설명합니다.
- **DPU와 DOCA가 AI 데이터 센터에서 수행하는 역할 결정**: DPU와 DOCA가 무엇이며, AI 데이터 센터에서 어떤 역할을 하는지 이해합니다.
- **NVIDIA 인증 시스템 사용의 이점 평가**: NVIDIA 인증 시스템을 사용하는 이점이 무엇인지 평가합니다.

---

### **핵심 내용 분석**

#### **1. NVIDIA 데이터 센터 플랫폼 소개 및 컴퓨트 플랫폼 구축을 위한 고려사항**

- **현대 데이터 센터의 역할**: 고성능 컴퓨팅과 AI를 사용하여 세계에서 가장 중요한 과학, 산업, 빅데이터 문제를 해결하는 데 핵심적입니다.
- **가속 컴퓨팅의 중요성**:
  - **풀 스택 도전**: 최적의 성능을 달성하기 위해 기술 스택의 여러 계층에서 다양한 구성 요소를 최적화하고 통합해야 합니다.
  - **데이터 센터 규모 문제**: 현대의 데이터 센터는 사실상 하나의 컴퓨터로서, 애플리케이션이 전체 데이터 센터에 걸쳐 실행됩니다. 따라서 데이터 센터 내의 다양한 구성 요소를 최적화하는 것이 중요합니다.
- **NVIDIA의 컴퓨팅 삼위일체**:
  - **GPU**: 그래픽과 AI에 필요한 대규모 병렬 처리를 수행하는 가속 컴퓨팅을 제공합니다.
  - **CPU**: 기본적인 단일 스레드 애플리케이션 등의 일반적인 애플리케이션 처리를 수행합니다.
  - **DPU**: 통신 처리, 압축, 암호화 등 데이터 집약적인 기능을 처리하여 데이터 센터의 효율적인 운영을 지원합니다.
  - **GPU, DPU, CPU의 조합**이 새로운 컴퓨팅의 단위가 됩니다.
- **NVIDIA의 기술 스택 구성 요소**:
  - **하드웨어 기술**: GPU, CPU, DPU 등 서버 구축의 기반이 되는 기술.
  - **소프트웨어 스택**: GPU와 DPU를 위한 프로그래밍 모델인 **CUDA**와 **DOCA**, 그리고 다양한 소프트웨어 라이브러리(예: CUDA-X).
  - **애플리케이션 프레임워크**: 특정 도메인에 맞게 설계된 프레임워크(예: Riva, DRIVE, Merlin 등).

#### **2. 가속 시스템과 AI 컴퓨팅 플랫폼**

- **가속 시스템의 진화**:
  - 모든 스마트폰이 그래픽과 AI를 위한 프로세서를 갖추고 있듯이, 모든 서버와 워크스테이션도 AI, 시각화, 자율 머신 등 현대의 애플리케이션을 구동하기 위해 컴퓨팅 가속기를 갖추게 될 것입니다.
  - 많은 시스템이 **DPU(Data Processing Unit)**를 포함하여 네트워크, 스토리지, 보안 서비스를 가속화합니다.
- **컴퓨팅 플랫폼의 옵션**:
  - **클라우드 서비스 제공업체(CSP)**:
    - **이점**: 관리 및 유지 보수 없이 컴퓨팅 인프라와 리소스에 액세스 가능.
    - **추후 학습**: 클라우드 기반 솔루션은 이후 단원에서 자세히 다룰 예정.
  - **OEM 시스템**:
    - **유연성**: NVIDIA는 여러 신뢰할 수 있는 인증된 공급업체와 협력하여 즉시 사용 가능한 구성 요소로 솔루션을 구축할 수 있습니다.
  - **NVIDIA DGX 시스템**:
    - **목적 구축**: 네트워킹, 스토리지, 컴퓨팅 등 최적화된 구성 요소로 구축.
    - **이점**: NVIDIA의 전문 지식을 활용하여 솔루션의 배포와 유지 관리를 지원받을 수 있습니다.

#### **3. AI 애플리케이션 개발 워크플로우**

- **개요**:
  - 아이디어 단계에서 시작하여 프로덕션 환경에서 실행되는 훈련된 모델로 실현되는 워크플로우를 따릅니다.
  - 데이터 과학자, 데이터 엔지니어, 비즈니스 분석가, DevOps, 애플리케이션 개발자가 협력하여 여러 단계를 거칩니다.
- **클라우드 기반 GPU 솔루션의 이점**:
  - **고밀도 컴퓨팅 리소스에 대한 액세스**: 물리적 데이터 센터를 구축할 필요 없이 언제 어디서나 액세스 가능.
  - **가상 데스크톱, 애플리케이션, 워크스테이션**: 데이터 과학자, 연구원, 개발자가 자신의 데스크에서 GPU 가속화된 AI와 데이터 분석을 수행할 수 있습니다.
  - **비용 절감**: GPU 가속화된 데이터 센터는 더 적은 서버로 어떤 규모에서도 컴퓨팅 및 그래픽 워크로드에 대한 획기적인 성능을 제공합니다.
  - **보안 유지**: 민감한 데이터를 저장, 처리, 분석하면서 운영 보안을 유지할 수 있습니다.
- **엣지에서의 AI**:
  - **요구사항**: 실시간으로 결정을 내리고, 산업 전반에 걸쳐 자동화된 인텔리전스를 제공할 수 있는 확장 가능한 가속 플랫폼이 필요합니다.
  - **NVIDIA Jetson 플랫폼**: 엣지 배포를 위해 설계된 NVIDIA 플랫폼으로, 스토어, 제조, 병원, 스마트 시티 등에서 활용됩니다.