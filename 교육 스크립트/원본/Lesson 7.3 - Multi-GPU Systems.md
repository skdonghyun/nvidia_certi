# Lesson 7.3 - Multi-GPU Systems

0:01
Now that we've covered the GPU and CPU solutions for AI data centers, let's see how to scale up with multi GPU systems.
Play video starting at ::10 and follow transcript0:10
As an AI solution scales, it's key to know how to scale solutions based on increased workload demand. There are two ways to scale the scale-up, which is referred to as multi-GPU, and scale-out, which is referred to as multi-node. Lets compare each one of these options.
Play video starting at ::30 and follow transcript0:30
Multi-GPU scaling refers to adding more GPUs to a single node to increase its computational power, whereas multi-node scaling refers to adding more nodes to a system to increase its overall processing power. In terms of hardware requirements, multi-GPU scaling requires a node with multiple GPUs and a high speed interconnect to allow communication between the GPUs. While multi-node scaling requires multiple nodes, each with its own processing capabilities connected through a network. Multi-GPU scaling usually involves distributing data across the GPUs for parallel processing, whereas multi-node scaling involves distributing data across nodes for parallel processing. Multi-GPU scaling also requires load balancing between the GPUs, while multi-node scaling requires load balancing between the nodes. Lastly, multi-node scaling provides better failure tolerance compared to multi-GPU scaling as the failure of one node does not affect the overall system, whereas in multi-GPU scaling the failure of one GPU can affect the entire system. In the following slides, well cover the scale up option or multi-GPU.
Play video starting at :1:43 and follow transcript1:43
As AI solutions become more complex, there is an exceptional growth in the computing capacity. To meet this challenge, developers have turned to multi-GPU system implementations. In multi-GPU systems, one of the keys to continued performance scaling is flexible, high bandwidth communication between GPUs in the system. In traditional servers, this is accomplished by using PCIE. However, as workloads continue to get bigger and GPUs are able to churn through data faster, the bandwidth provided by PCIE has proved to be a bottleneck.
Play video starting at :2:20 and follow transcript2:20
To meet the challenge of communication between GPUs in a system. NVIDIA introduced NV link chip to chip interconnect to connect multiple GPUs at speeds significantly faster than what PCIE offers, allowing GPUs to communicate and share memory between themselves at incredibly high speeds. But in all to all communications where all GPUs need to communicate with one another, this implementation requires certain GPU pairs to communicate over a much slower PCIE data path. To take GPU server performance to the next level and scale beyond eight GPUs in a single server a more advanced solution was needed.
Play video starting at :3: and follow transcript3:00
With AI and HPC workloads, there are many common operations which require one GPU to talk to all the other GPUs in the system, such as distributing data to the other GPUs. Often this happens on all GPUs simultaneously, leading to many so called all-to-all operations. NVIDIA NV switch technology enables direct communication between any GPU pair without bottlenecks. Each GPU uses NVLink interconnects to communicate with all NVSwitch fabrics. This provides the maximum amount of bandwidth to communicate across GPUs over the links.
Play video starting at :3:43 and follow transcript3:43
Each DGX H 100 system has 8 H100 GPUs. NVIDIA NVSwitch provides high bandwidth inner GPU communication.
Play video starting at :3:54 and follow transcript3:54
The system is configured with ten NVIDIA connectX-7 network interfaces, each with a bandwidth of 400 gigabits per second. It can provide up to 1 terabyte per second of peak bi-directional network bandwidth.
Play video starting at :4:8 and follow transcript4:08
When a system is configured with two Intel Xeon Platinum 8480 C processors, it has a total of 112 cores, which means that it can handle a large number of simultaneous tasks and computations. The DGX H100 has 2 terabytes of system memory, which is a massive amount of memory that can be used to store and process large amounts of data.
Play video starting at :4:31 and follow transcript4:31
The DGX H100 is configured with 30 terabytes of NVMe SSD storage. This large amount of high speed storage can be used to store and access data quickly. AI performance of 32 quadrillion floating point operations per second, NVIDIA DGX systems are shipped preinstalled with DGX OS to provide a turnkey solution for running AI and analytics workloads. NVIDIA DGX OS provides a customized installation of Ubuntu Linux with system specific optimizations and configurations, additional drivers, and diagnostic and monitoring tools. It provides a stable, fully tested, and supported OS to run AI machine learning and analytics applications on DGX supercomputers.
Play video starting at :5:19 and follow transcript5:19
Let's look at the physical specifications of the DGX H100 system.
Play video starting at :5:25 and follow transcript5:25
It is an eight rack unit high chassis that fits in a standard 19 inch rack. The system is quite heavy and requires a mechanical lift to help get it out of the packaging and safely installed in a rack, the DGX H100 is physically constructed from a handful of modules, each handling discrete functions in the system. At the front shown on the far left side, we have the gold bezel that should be familiar to anyone who has seen a DGX before. Behind the bezel are the 12 dual fan modules. Below those are the eight U2 NVMe drives used as a data cache, and the front console board with VGA and USB ports to connect a crash cart too. The front cage includes a power distribution board that connects the system to the power supplies shown at the rear of the system. That front cage also holds a mid plane, which handles communication between the motherboard tray, the GPU tray, and the components at the front of the system. The DGX H100 system offers impressive GPU to GPU connectivity thanks to the presence of four fourth generation NVLink switches. These switches enable high speed data transfer and parallel processing capabilities among the installed GPUs, making it suitable for AI and data intensive tasks. The GPU tray is found at the top rear of the system with the motherboard tray underneath, and the chassis holds everything together in a nice modular package.
Play video starting at :6:54 and follow transcript6:54
The NVIDIA DGX B200 system is the latest addition to the NVIDIA DGX platform. This unified AI platform defines the next chapter of generative AI. Equipped with 8 NVIDIA Blackwell GPUs interconnected with fifth generation NVIDIA NVLink, it delivers breakthrough performance for the world's most complex AI problems, such as large language models and natural language processing. With a massive 1.4TB of GPU memory, dual Intel Xeon Platinum 8570 processors, 2TB of system memory, 72 petaflops FP8 training performance, and 144 petaflops FP4 inference performance. The DGX B200 is well suited to handle any enterprise AI workload.
Play video starting at :7:41 and follow transcript7:41
NVIDIA GB200 NVL 72 is a multi-node, liquid cooled rack scale system for the most compute intensive workloads. It combines 36 Grace CPU's and 72 Blackwell GPU's interconnected by fifth generation NVLink. With its liquid cooled racks, the GB200 NVL 72 reduces a data center's energy consumption while increasing its compute density. The combination of 72 NVLink connected Blackwell GPUs with a large unified memory over a 130 TB/s compute fabric creates an exaflop AI supercomputer in a single rack. As a result, the NVIDIA GB 200 NVL72 delivers trillion-parameter LLM training and real-time inference.