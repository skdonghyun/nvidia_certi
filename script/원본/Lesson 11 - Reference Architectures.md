# Lesson 11 - Reference Architectures

0:07
Welcome to unit 11, we'll be covering NVIDIA reference architectures.
Play video starting at ::14 and follow transcript0:14
In this unit we'll give an overview of some reference architectures and their benefits. Next, we'll use the DGX BasePOD reference architecture to show the type of information that can be found in a reference architecture. Finally, well look briefly at the DGX SuperPOD and some additional reference architectures.
Play video starting at ::34 and follow transcript0:34
By the end of this unit you should be able explain the value of reference architectures, describe the information found in reference architectures. Identify available NVIDIA reference architectures and describe the components in the NVIDIA BasePOD reference architecture. Lets begin with an overview of reference architectures. Dense computing environments include many components. There are multiple servers for compute, networking fabrics that connect the systems, storage for data and management servers. Designing systems to get maximum performance can be very difficult. Reference architectures are documents showing a recommended design for the implementation of a system. It uses best of breed designs to provide high-performance solutions.
Play video starting at :1:29 and follow transcript1:29
NVIDIA has several reference architectures for datacenter scale computing environments. These include the DGX BasePOD and the DGX SuperPOD, reference architectures. Reference architectures are design documents that are based on the best practices and design principles to get the most out of the system. Reference architectures can be used as a foundation for building designs using systems and components. Some of the benefits of using a reference architecture they show how a specific design can help solve problems. They give a foundational design that can be tailored to meet an organization's needs. They reduce cost and time for design and planning, which can lead to a faster solution, and they improve quality and reliability by reducing complexity.
Play video starting at :2:20 and follow transcript2:20
Let's review the reference architecture for the NVIDIA DGX BasePOD. We will look through the detailed information provided in this reference architecture, including the components in a DGX BasePOD and a variety of configurations available. The NVIDIA DGX BasePOD provides the underlying infrastructure and software to accelerate deployment and execution of AI workloads. It is an integrated solution consisting of NVIDIA DGX systems, NVIDIA networking systems, NVIDIA Base Command software, and NVIDIA AI Enterprise software as well as Partner Storage. Its reference architecture defines the components and connections to create a DGX BasePOD with up to 16 DGX, B200 or H100 systems. It covers the variety of configurations for a DGX BasePOD. The reference architecture document can be accessed via the link provided.
Play video starting at :3:19 and follow transcript3:19
With DGX BasePOD, we've taken proven NVIDIA networking products, plugged in our leading DGX systems for compute, paired that with storage solutions from trusted NVIDIA partners, and then used NVIDIA base command to glue it together. Combined with NVIDIA AI, enterprise, and MLOps offerings, this turns what would otherwise be a collection of world leading components into a cohesive, full stack solution. As we'll see, the BasePOD reference architecture covers these concepts in detail to make it easier to incorporate the components into a system that solves problems. In the next few slides, we'll review the components of the DGX BasePOD reference architecture.
Play video starting at :4: and follow transcript4:00
As we'll see, the BasePOD reference architecture covers these concepts in detail to make it easier to incorporate the components into a system that solves problems. In the next few slides, we'll review the components of the DGX BasePOD reference architecture.
Play video starting at :4:18 and follow transcript4:18
The DGX BasePOD reference architecture provides overviews of the DGX B200 system and the DGX H100 system, as well as their specifications and connections. The DGX B200 system includes eight NVIDIA B200 GPU's and can deliver 72 petaflops FP8 training performance and 144 petaflops FP4 inference performance, making it well suited to handle any enterprise AI workload. The DGX H100 system includes 8 NVIDIA H100 GPU's and has a performance of 32 petaflops FP8, making it a great all around system for AI development. DGX systems have one gigabit Ethernet port for out of band management through the baseboard management controller. The baseboard management controller allows for out of band remote management of the device even when the system is powered off.
Play video starting at :5:11 and follow transcript5:11
The next component that the NVIDIA DGX BasePOD reference architecture covers is the connectx-7 network adapter. This adapter can be configured for InfiniBand or Ethernet connections. Typically, InfiniBand connections are used for the compute network and Ethernet is used for the storage in band management and out of band management networks. The DGX BasePOD reference architecture also includes an overview of the NVIDIA switches that can be employed in DGX BasePOD configurations. This includes the QM9700 and QM8700 InfiniBand switches. As an example, the QM9700 NDR InfiniBand switch with 400 gigabits per second is used with the DGX H100 system, NDR stands for next data rate. The SN 5600 Ethernet switch is used for GPU to GPU fabrics and offers speeds between 10 gigabits Ethernet and 800 gigabits Ethernet. The SN4600 is used for in band management and can also be used for storage fabrics. It offers speeds between1 gigabit Ethernet and 200 gigabits Ethernet. The SN2201 Ethernet switch is used for out of band management connections in the base pod configuration with speeds between 1 gigabit Ethernet and 100 gigabits Ethernet.
Play video starting at :6:32 and follow transcript6:32
The final configuration in the reference architecture is the DGX H100 base pod with NDR 200 gigabits per second InfiniBand connectivity for the compute network using the QM9700 switches. This configuration uses the connectx-7 network adapters for connections. The storage and management network is an Ethernet network using the SN4600 switches. This design works for 2 to 16 DGX H100 systems. This exact same DGX BasePOD reference architecture can also be used with the DGX B200 systems. Now we'll take a high level look at the DGX SuperPOD and some additional reference architectures.
Play video starting at :7:15 and follow transcript7:15
The NVIDIA DGX SuperPOD is the next generation artificial intelligence supercomputing infrastructure based on the DGX B200 system or the DGX H100 system. The reference architecture design introduces compute building blocks called scalable units, or SU, enabling the modular deployment of a full 127 node SuperPOD with the DGX B200 or H100 systems. The DGX SuperPOD design includes NVIDIA networking switches, software storage, and NVIDIA AI enterprise, a fully supported software suite optimized to streamline AI development and deployment. A DGX SuperPOD with InfiniBand networking is recommended to enable data scientists to train large language models like GPT-4. The DGX SuperPOD reference architecture has been deployed at customer data centers and cloud service providers around the world.
Play video starting at :8:10 and follow transcript8:10
NVIDIA also has reference architectures that are not based on specific NVIDIA servers. Some examples include the NVIDIA AI enterprise reference architecture and the Cloudera data platform reference architecture. These reference architectures include node configurations in addition to the network topology, deployment topology, and other resources to get the most out of these designs. Now that you've completed this unit, you should be able to, explain the value of reference architectures, describe the information found in reference architectures. Identify available NVIDIA reference architectures, and describe the components in the NVIDIA BasePOD reference architecture.
Play video starting at :8:54 and follow transcript8:54
Don't stop here, continue the learning journey with Unit 12 AI in the Cloud see you in the next unit.